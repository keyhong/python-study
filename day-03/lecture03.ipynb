{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 자료 출처 : https://www.youtube.com/watch?v=JExG53x9LBo&list=PLnp1rUgG4UVa3XeP0fsp1lrO3EVO-Xwai \n",
    "# pandas 자료 출처 : Gyuwon Hong\n",
    "\n",
    "# 검은 테마로 설정해서 보시길!\n",
    "# 제 pandas 버전은 1.5.3 입니다. 현재 PyPi에서 설치가능한 latest는 2.0.3 버전 입니다.\n",
    "# 다소 변동사항이 있으나, 크게 본질은 바뀌지 않으니 최고의 개발자들이 어떻게 패키지를 변화시키고 발전 시키는 지 흐름을 읽어보세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\"> numpy </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통계, 분석, AI 분야의 라이브러리 내부에 다양한 수치연산 필요함\n",
    ">> 수치연산을 얼마나 효율적으로 처리하는가에 따라 성능에 많은 영향을 줌\n",
    ">> numpy는 ndarray라는 자료를 바탕으로 강력한 연산 기능 제공\n",
    "\n",
    "# numpy와 다른 python 패키지의 관계\n",
    "\n",
    "numpy : 난수 생성, 행렬 연산, 간단한 통계 분석\n",
    "\n",
    "##############################\n",
    "+ scipy : 수치해석\n",
    "+ sympy : 기호계산\n",
    "+ pandas : 데이터 처리\n",
    "+ tensorflow : ML / DL\n",
    "+ matplotlib / seaborn : 그래픽\n",
    "##############################\n",
    "\n",
    "= 간결한 코드 구현\n",
    "= 빠른 연산 속도\n",
    "= numpy 보다 복잡한 형태의 자료 생성, 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\"> numpy.ndarray 만들기 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's move function <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.array.html\" style=\"color: yellow; font-size: 24pt;\"> numpy.array() </a> document site !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) numpy.array는 자료형이 아니다. numpy.ndarray의 object를 만들어내는 method다. 클래스와 메서드를 정확히 구분해야 한다.\n",
    "## (2) numpy.array가 파이썬에서 일반적으로 클래스명을 쓸 때 사용하는 Camel Case(example: Numpy, ExampleClass)가 아닌 것은, numpy는 c로 구현이 되었기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n",
      "      like=None)\n",
      "\n",
      "Create an array.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "object : array_like\n",
      "    An array, any object exposing the array interface, an object whose\n",
      "    __array__ method returns an array, or any (nested) sequence.\n",
      "    If object is a scalar, a 0-dimensional array containing object is\n",
      "    returned.\n",
      "dtype : data-type, optional\n",
      "    The desired data-type for the array.  If not given, then the type will\n",
      "    be determined as the minimum type required to hold the objects in the\n",
      "    sequence.\n",
      "copy : bool, optional\n",
      "    If true (default), then the object is copied.  Otherwise, a copy will\n",
      "    only be made if __array__ returns a copy, if obj is a nested sequence,\n",
      "    or if a copy is needed to satisfy any of the other requirements\n",
      "    (`dtype`, `order`, etc.).\n",
      "order : {'K', 'A', 'C', 'F'}, optional\n",
      "    Specify the memory layout of the array. If object is not an array, the\n",
      "    newly created array will be in C order (row major) unless 'F' is\n",
      "    specified, in which case it will be in Fortran order (column major).\n",
      "    If object is an array the following holds.\n",
      "\n",
      "    ===== ========= ===================================================\n",
      "    order  no copy                     copy=True\n",
      "    ===== ========= ===================================================\n",
      "    'K'   unchanged F & C order preserved, otherwise most similar order\n",
      "    'A'   unchanged F order if input is F and not C, otherwise C order\n",
      "    'C'   C order   C order\n",
      "    'F'   F order   F order\n",
      "    ===== ========= ===================================================\n",
      "\n",
      "    When ``copy=False`` and a copy is made for other reasons, the result is\n",
      "    the same as if ``copy=True``, with some exceptions for 'A', see the\n",
      "    Notes section. The default order is 'K'.\n",
      "subok : bool, optional\n",
      "    If True, then sub-classes will be passed-through, otherwise\n",
      "    the returned array will be forced to be a base-class array (default).\n",
      "ndmin : int, optional\n",
      "    Specifies the minimum number of dimensions that the resulting\n",
      "    array should have.  Ones will be prepended to the shape as\n",
      "    needed to meet this requirement.\n",
      "like : array_like, optional\n",
      "    Reference object to allow the creation of arrays which are not\n",
      "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "    the ``__array_function__`` protocol, the result will be defined\n",
      "    by it. In this case, it ensures the creation of an array object\n",
      "    compatible with that passed in via this argument.\n",
      "\n",
      "    .. versionadded:: 1.20.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "out : ndarray\n",
      "    An array object satisfying the specified requirements.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "empty_like : Return an empty array with shape and type of input.\n",
      "ones_like : Return an array of ones with shape and type of input.\n",
      "zeros_like : Return an array of zeros with shape and type of input.\n",
      "full_like : Return a new array with shape of input filled with value.\n",
      "empty : Return a new uninitialized array.\n",
      "ones : Return a new array setting values to one.\n",
      "zeros : Return a new array setting values to zero.\n",
      "full : Return a new array of given shape filled with value.\n",
      "\n",
      "\n",
      "Notes\n",
      "-----\n",
      "When order is 'A' and `object` is an array in neither 'C' nor 'F' order,\n",
      "and a copy is forced by a change in dtype, then the order of the result is\n",
      "not necessarily 'C' as expected. This is likely a bug.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> np.array([1, 2, 3])\n",
      "array([1, 2, 3])\n",
      "\n",
      "Upcasting:\n",
      "\n",
      ">>> np.array([1, 2, 3.0])\n",
      "array([ 1.,  2.,  3.])\n",
      "\n",
      "More than one dimension:\n",
      "\n",
      ">>> np.array([[1, 2], [3, 4]])\n",
      "array([[1, 2],\n",
      "       [3, 4]])\n",
      "\n",
      "Minimum dimensions 2:\n",
      "\n",
      ">>> np.array([1, 2, 3], ndmin=2)\n",
      "array([[1, 2, 3]])\n",
      "\n",
      "Type provided:\n",
      "\n",
      ">>> np.array([1, 2, 3], dtype=complex)\n",
      "array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
      "\n",
      "Data-type consisting of more than one element:\n",
      "\n",
      ">>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
      ">>> x['a']\n",
      "array([1, 3])\n",
      "\n",
      "Creating an array from sub-classes:\n",
      "\n",
      ">>> np.array(np.mat('1 2; 3 4'))\n",
      "array([[1, 2],\n",
      "       [3, 4]])\n",
      "\n",
      ">>> np.array(np.mat('1 2; 3 4'), subok=True)\n",
      "matrix([[1, 2],\n",
      "        [3, 4]])\n",
      "\u001b[1;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "# jupyter에서 DocString 출력하기\n",
    "np.array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\"> Element By Element 연산 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list로 각 element 간의 연산을 구현할 때 (두 list 객체를 zip으로 엮어 iteration을 돌림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "list_a: List[int] = [1, 2, 3]\n",
    "list_b: List[int] = [4, 5, 6]\n",
    "list_c: List[int] = []\n",
    "\n",
    "for elem_a, elem_b in zip(list_a, list_b):\n",
    "    list_c.append(elem_a + elem_b)\n",
    "\n",
    "print(list_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.array로 각 element 간의 연산을 구현할 때 (두 ndarray 객체 간의 연산자 사용이 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# np.array 코드\n",
    "ndarray_a: np.array = np.array([1, 2, 3])\n",
    "ndarray_b: np.array = np.array([4, 5, 6])\n",
    "\n",
    "ndarray_c = ndarray_a + ndarray_b\n",
    "print(ndarray_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그럼 list 객체끼리 연산자를 사용하면? element 간의 연산이 아닌, list를 extend() 하는 것과 같다. ( list.append() != list.extend() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print([1, 2, 3] + [4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\"> 내부 Element 변경 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list로 Element 간의 연산을 구현할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3행 | 4열 | 2차원 리스트\n",
      "[[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list\n",
    "test_lst = [ [1, 2, 3, 4] for _ in range(3) ]   \n",
    "print(\"# 3행 | 4열 | 2차원 리스트\", test_lst, \"\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ndarray로 Element 간의 연산을 구현할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3행 | 4열 | 2차원 np.ndarray\n",
      "[[1 2 3 4]\n",
      " [1 2 3 4]\n",
      " [1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "# ndarray\n",
    "test_ndarray = np.array(test_lst) \n",
    "print(\"# 3행 | 4열 | 2차원 np.ndarray\", test_ndarray, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list로 내부 element 값을 바꿀 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 1, 2], [3, 4, 1, 2], [3, 4, 1, 2]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exchange_list(input_lst: List[int]) -> List[int]: \n",
    "    \n",
    "    output_lst = []\n",
    "    \n",
    "    # iteration\n",
    "    for row in input_lst:\n",
    "        row[2], row[3], row[0], row[1] = row\n",
    "\n",
    "        # append element\n",
    "        output_lst.append(row)\n",
    "\n",
    "    return output_lst\n",
    "\n",
    "output_lst = exchange_list(test_lst)\n",
    "output_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nd.array로 내부 Element 값을 바꿀 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 1, 2],\n",
       "       [3, 4, 1, 2],\n",
       "       [3, 4, 1, 2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exchange_ndarray(input_ndarray: np.ndarray) -> np.ndarray:\n",
    "    return input_ndarray[ :, [2, 3, 0, 1]]\n",
    "\n",
    "\n",
    "output_ndarray = exchange_ndarray(test_ndarray)\n",
    "output_ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\"> numpy는 list 보다 훨씬 빠르다 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# list\n",
      "750 ns ± 43.7 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "\n",
      "# ndarray\n",
      "4.51 µs ± 209 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"# list\")\n",
    "%timeit exchange_list(test_lst) # ms (마이크로초)\n",
    "\n",
    "print(\"\\n# ndarray\")\n",
    "%timeit exchange_ndarray(test_ndarray) # µs (밀리초)\n",
    "\n",
    "# 1 ms == 0.001 µs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"greenyellow\"> ★ Why? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndarray가 list 보다 빠른 이유?\n",
    "\n",
    "https://github.com/numpy/numpy/blob/maintenance/1.7.x/numpy/core/include/numpy/ndarraytypes.h#L646\n",
    "\n",
    "list\n",
    "https://hg.python.org/cpython/file/3.6/Include/listobject.h#l23\n",
    "\n",
    "int\n",
    "https://hg.python.org/cpython/file/3.6/Include/longintrepr.h/#l85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\"> numpy.ndarray attribute </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_function__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__dlpack__',\n",
       " '__dlpack_device__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attribute 확인한는 builtin_function_or_method\n",
    "dir(np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 Attribute\n",
    "\n",
    "ndim : int\n",
    "   Number of array dimensions.\n",
    "\n",
    "shape : tuple of ints\n",
    "   Tuple of array dimensions.\n",
    "\n",
    "size : intm\n",
    "   Number of elements in the array.\n",
    "\n",
    "itemsize : int\n",
    "   Length of one array element in bytes.\n",
    "\n",
    "dtype : dtype object\n",
    "   Data-type of the array’s elements.\n",
    "\n",
    "\n",
    "strides : tuple of ints\n",
    "   Tuple of bytes to step in each dimension when traversing an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndarray.ndim         2\n",
      "ndarray.shape        (2, 3)\n",
      "ndarray.size         6\n",
      "ndarray.dtype        int32\n",
      "ndarray.itemsize     4\n",
      "ndarray.strides      (12, 4)\n"
     ]
    }
   ],
   "source": [
    "# function : Print ndarray attribute \n",
    "def printInfo(ndarray):\n",
    "    data = [\"ndarray.ndim\", \"ndarray.shape\", \"ndarray.size\", \"ndarray.dtype\", \"ndarray.itemsize\", \"ndarray.strides\"]\n",
    "\n",
    "    for elem in data:\n",
    "        print(\"%-20s\" % elem, eval(elem))\n",
    "\n",
    "ndarray = np.array([[0, 1, 2], [3, 4, 5]], dtype=np.int32)\n",
    "printInfo(ndarray)\n",
    "\n",
    "# ndim     : shape[0] * shape[1]\n",
    "# shape    : (행의 개수, 열의 개수)\n",
    "# size     : 총 요소(element) 합계 (shape[0] * shape[1])\n",
    "# itemsize : dtype의 byte 수로 표현\n",
    "# strides  : 차원별로 이동할 때 사용되는 byte 수 (1차원 간의 이동 : 3개 elem 12byte) (1차원 내부의 2차원 간의 이동 : elem 간의 이동 4byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to change ndim?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndarray.ndim         3\n",
      "ndarray.shape        (2, 3, 3)\n",
      "ndarray.size         18\n",
      "ndarray.dtype        int64\n",
      "ndarray.itemsize     8\n",
      "ndarray.strides      (72, 24, 8)\n"
     ]
    }
   ],
   "source": [
    "ndarray = np.array(\n",
    "    [\n",
    "        [\n",
    "            [0, 1, 2],\n",
    "            [3, 4, 5],\n",
    "            [6, 7, 8]\n",
    "        ],[\n",
    "            [0, 1, 2],\n",
    "            [3, 4, 5],\n",
    "            [6, 7, 8]\n",
    "        ]\n",
    "    ]\n",
    "    , dtype=np.int64)\n",
    "printInfo(ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\"> pandas </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흔히 RDB(Relational DatabBase)에 사용하는 행과 열로 이루어진 구조의 데이터를 다루는 데 특화된 라이브러리이다.\n",
    "# pandas하면 pandas.DataFrame만을 생각하고 동일시 하는데, 그렇게 생각하면 데이터 전처리하는 데 큰 오류를 범한다.\n",
    "# 왜냐면? pandas.DataFrame의 특정 열을 추출하면 pandas.Series 타입으로 나오기 때문이다.\n",
    "# 또 numpy의 ndarray를 pandas.Series에 대입하여 값을 바꾸기도 한다.\n",
    "\n",
    "# 그리고 spark에도 DataFrame이라는 자료형이 있다. pyspark.sql.DataFrame 이라는 자료형이다.\n",
    "# 그러니까 데이터를 다루기 전 정확한 라이브러리의 모듈과 자료형을 이해하고 써야 한다.\n",
    "# 그렇지 않으면 여러 플랫폼을 같이 쓸 때, 코드 상의 혼돈을 초래할 수 밖에 없다.\n",
    "\n",
    "# 정확히 자료형을 이해해야 그 객체 안에 있는 메서드를 도큐먼트에서 찾아서 활용할 수 있고, 그러면 인터넷에 남이 쓴 레퍼런스 볼 일이 적어진다.\n",
    "# 인터넷에 있는 레퍼런스는 정확한 게 아닌 게 상당히 많다.\n",
    "# 도큐먼트 보는 건 프로그래밍을 하는 사람에게 선택이 아니라 필수사항이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris = iris[:5].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       |       | Column Index 0 | Column Index 1 | Column Index 2 | Column Index 3 | Column Index 4 |\n",
    "|:-----:|:-----:| :------------------:|:-----------:|:------------:|:-----------:|:-------:|\n",
    "|  |index  | sepal_length      | sepal_width | petal_length | petal_width | species |\n",
    "| Row Index 0 | 0     | 5.1      | 3.5 | 1.4 | 0.2 | setosa |\n",
    "| Row Index 1 | 1     | 4.9      | 3.0 | 1.4 | 0.2 | setosa |\n",
    "| Row Index 2 | 2     | 4.7      |3.2  | 1.3 | 0.2 | setosa|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\"> Row Index </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# index values :  RangeIndex(start=0, stop=5, step=1)\n",
      "<class 'pandas.core.indexes.range.RangeIndex'>\n",
      "\n",
      "    sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임의 인덱스는 기본적으로 row의 인덱스를 말한다.\n",
    "print(\"# index values : \", iris.index)\n",
    "\n",
    "# row index의 타입은 pandas.core.indexes.range.RangeIndex 이다.\n",
    "print(type(iris.index))\n",
    "\n",
    "\"\"\"\n",
    "class RangeIndex(Index):\n",
    "\n",
    "    Immutable Index implementing a monotonic integer range.\n",
    "\n",
    "    RangeIndex is a memory-saving special case of an Index limited to representing\n",
    "    monotonic ranges with a 64-bit dtype. Using RangeIndex may in some instances\n",
    "    improve computing speed.\n",
    "\n",
    "    This is the default index type used\n",
    "    by DataFrame and Series when no explicit index is provided by the user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start : int (default: 0), range, or other RangeIndex instance\n",
    "        If int and \"stop\" is not given, interpreted as \"stop\" instead.\n",
    "    stop : int (default: 0)\n",
    "    step : int (default: 1)\n",
    "    dtype : np.int64\n",
    "        Unused, accepted for homogeneity with other index types.\n",
    "    copy : bool, default False\n",
    "        Unused, accepted for homogeneity with other index types.\n",
    "    name : object, optional\n",
    "        Name to be stored in the index.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\", iris)\n",
    "# name 파라미터에서 볼 수 있듯이, index에 이름을 지정할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=5, step=1)\n"
     ]
    }
   ],
   "source": [
    "# range와 같이 start가 0에서 시작하며, stop, step에 있다.\n",
    "print(iris.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최고의 개발자들이 만드는 변화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 4], dtype='int64')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그런데, 0~4 사이의 인덱스에서 중간인 3을 드랍하면 어떻게 될까?\n",
    "index_drop_iris: pd.core.indexes.numeric.Int64Index  = iris.drop(3).index\n",
    "index_drop_iris\n",
    "\n",
    "# 타입이 Int64Index로 바껴 버렸다. (pandas 패키지의 core 폴더 안의 indexes 폴더 안의 numeric 모듈 안의 Int64Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그렇다고 항상 타입이 바뀌지는 않는다. 마지막 인덱스인 4를 드랍하면, 그래도 RangeIndex의 start, stop, step이 성사되어 타입이 유지된다.\n",
    "# start부터 stop까지 step의 간격이 유지되면 타입은 변하지 않는다.\n",
    "iris.drop(4).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ★★★ 근런데 pandas.Int64Index는 pandas 1.4.0 버전에서 앞으로 deprecated 될 예정이라는 말과 함께 NumericIndex를 권장한다. 내 판다스 버전은 1.5.3 이다. ★★★\n",
    "# https://pandas.pydata.org/pandas-docs/version/1.5/reference/api/pandas.Int64Index.html\n",
    "# 지금은 사라졌지만, 대체되는 NumericIndex 클래스의 소스 코드를 겨우 찾았다. Int64Index/UInt64Index/Float64Index를 통합시켜 버린 것 같다.\n",
    "\n",
    "Index = object # 상속받는 모듈이 없어서 Error를 막기 위해 임시로 최상위 클래스인 object로 두었다.\n",
    "\n",
    "class NumericIndex(Index):\n",
    "    \"\"\"\n",
    "    Immutable numeric sequence used for indexing and alignment.\n",
    "\n",
    "    The basic object storing axis labels for all pandas objects.\n",
    "    NumericIndex is a special case of `Index` with purely numpy int/uint/float labels.\n",
    "\n",
    "    .. versionadded:: 1.4.0\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like (1-dimensional)\n",
    "    dtype : NumPy dtype (default: None)\n",
    "    copy : bool\n",
    "        Make a copy of input ndarray.\n",
    "    name : object\n",
    "        Name to be stored in the index.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    Index : The base pandas Index type.\n",
    "    Int64Index : Index of purely int64 labels (deprecated).\n",
    "    UInt64Index : Index of purely uint64 labels (deprecated).\n",
    "    Float64Index : Index of  purely float64 labels (deprecated).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    An NumericIndex instance can **only** contain numpy int64/32/16/8, uint64/32/16/8 or\n",
    "    float64/32/16 dtype. In particular, ``NumericIndex`` *can not* hold Pandas numeric\n",
    "    dtypes (:class:`Int64Dtype`, :class:`Int32Dtype` etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변화가 끝이 아니다. 1.4.x 버전에서 앞으로 NumericIndex으로 대체한다고 했다가\n",
    "# 2.0.x 버전에서는 전혀 보이질 않고, pandas.Index로 바꿔 놓았다. 참.. 변화가 빠르다. 그래도 이런 부분들을 다 외울 필요는 없다.\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Index.html\n",
    "\n",
    "class Index(IndexOpsMixin, PandasObject):\n",
    "    \"\"\"\n",
    "    .. versionchanged:: 2.0.0 \n",
    "        \n",
    "        Changed in version 2.0.0: Index can hold all numpy numeric dtypes (except float16). Previously only int64/uint64/float64 dtypes were accepted.\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# pandas.Int64Index는 pandas 1.5.x 버전까지만 사용가능하다. 하지만 stable 버전이 2.0.0 버전이니 1.x 버전도 좀 지나면 쓰지 않고 pandas.Index로 이제는 바뀔 것이다.\n",
    "\n",
    "# 재미있는 요소다. 다시 한번 말하지만 이런 부분을 외울 필요는 없다. 프로그래밍에 감이 잡히면, 프로그래밍이 암기가 아니라 이해하고 활용하는 영역이라는 걸 깨닫게 된다.\n",
    "# 유사하게 Spark를 써보면 알겠지만, 2.X 버전부터는 1.X에서 따로 놀던 SQLContext, HiveContext, SparkContext를 합친 SparkSession이라는 통합된 Entry Point를 만들어 놓았다.\n",
    "# 이처럼 프로그래밍에서는 사용시 흩어진 요소들을 뭉치고 하나로 만들기도 한다.\n",
    "\n",
    "# 중요한 건 그 기반에 되는 CS 요소를 이해하는 것. 여전히 pandas.Index는 docstring에는 NumericIndex와 똑같은 설명을 적어두었다.\n",
    "# Immutable sequence used for indexing and alignment. (인덱싱 및 정렬에 사용되는 불변 시퀀스)\n",
    "# 불변 객체이고, indexing이 가능다는 성질은 여전히 남아 있다. 달라진 건 object와 float64, signed/unsiged int64를 합쳐 놓았다는 것이다.\n",
    "# 그리고 float16을 제외시켜 버렸다는 사실과 함께.\n",
    "\n",
    "# 플랫폼이든 프로그래밍이든 CS를 잘 알아야 변화에 빠르게 적응할 수 있다.\n",
    "# 그것이 되면 도큐먼트를 통해 변화를 캐치하고, 본질은 변하지 않는 다는 걸 알게 된다.\n",
    "# 그 본질이 변하게 될 경우 최소한 Major Version의 변화라도 나타날 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43miris\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m11111\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\wnhon\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5302\u001b[0m, in \u001b[0;36mIndex.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   5300\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   5301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value):\n\u001b[1;32m-> 5302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndex does not support mutable operations\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Index does not support mutable operations"
     ]
    }
   ],
   "source": [
    "iris.index[0] = 11111\n",
    "# 보다시피 Immutable(불변)이며, 인덱스의 element를 변경하려면 (TypeError: Index does not support mutable operations)가 난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"greenyellow\"> ★ What is Default Row Index ? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.range.RangeIndex'>\n",
      "RangeIndex(start=0, stop=5, step=1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 소스에서 처음 읽을 때, index의 default 타입은 pandas.core.indexes.range.RangeIndex 이다.\n",
    "# pandas.core.indexes.range.RangeIndex는 2.x 버전에도 여전히 존재한다.\n",
    "index_reset_iris: pd.core.indexes.range.RangeIndex = iris.reset_index(drop=True).index \n",
    "print(type(index_reset_iris))\n",
    "\n",
    "# 보통 pandas.DataFrame.reset_index()로 데이터프레임의 인덱스를 초기화 시키는 데, 이때 RangeIndex(start=0, stop=(데이터프레임의 행수), step=1)로 들어간다는 것이다.\n",
    "print(iris.reset_index(drop=True).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱스 내부 값을 바꾸고 싶다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1000, 1001, 1002, 1003, 1004], dtype='int64')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아까 봤듯 index는 immutable하기 때문에 개별 요소를 바꿀 수 없다.\n",
    "# 하지만, index 개수와 동일한 size의 container type의 객체를 넣으면 바뀐다. \n",
    "# 이는 RangeIndex에서 Int64Index로 바꾸겠다는 말이다.\n",
    "\n",
    "iris.index = [ i for i in range(1_000, 1_000 + len(iris)) ]\n",
    "iris.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\"> Column Index </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임의 컬럼에도 인덱스로 접근할 수 있다.\n",
    "# 다만 pandas.DataFrame.index 로 접근하는 게 아니라 pandas.DataFrame.columns로 접근하다\n",
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼의 타입은 pandas.core.indexes.base.Index이다.\n",
    "# 보통 컬럼으로 문자열을 지정하기 때문에 문자열을 담을 수 있는 Index 객체가 온 것이다.\n",
    "# 아까 pandas 2.X 버전부터는 pandas.Index가 NumericIndex를 대체한다고 했다.\n",
    "# 근데, pandas.Index에는 default parameter로 dtype이 있는 데, default value가 object이다.\n",
    "# 그래서 pandas.Index라는 객체는 signed/unsigned Int64, Float64, Object 타입의 element를 담을 수 있는 컨테이너라고 보면 된다.\n",
    "type(iris.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그러면 컬럼에 문자열이 아닌 Integer를 넣으면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1    2    3    4       5\n",
      "0  5.1  3.5  1.4  0.2  setosa\n",
      "1  4.9  3.0  1.4  0.2  setosa\n",
      "2  4.7  3.2  1.3  0.2  setosa\n",
      "3  4.6  3.1  1.5  0.2  setosa\n",
      "4  5.0  3.6  1.4  0.2  setosa \n",
      "\n",
      "     1    2    3    4       5\n",
      "0  5.1  3.5  1.4  0.2  setosa\n",
      "1  4.9  3.0  1.4  0.2  setosa\n",
      "2  4.7  3.2  1.3  0.2  setosa\n",
      "3  4.6  3.1  1.5  0.2  setosa\n",
      "4  5.0  3.6  1.4  0.2  setosa \n",
      "\n",
      "     0    1    2    3       4\n",
      "0  5.1  3.5  1.4  0.2  setosa\n",
      "1  4.9  3.0  1.4  0.2  setosa\n",
      "2  4.7  3.2  1.3  0.2  setosa\n",
      "3  4.6  3.1  1.5  0.2  setosa\n",
      "4  5.0  3.6  1.4  0.2  setosa \n",
      "\n",
      "Enum을 상속받은 EnumClass는 Iterable한 객체!\n",
      "\n",
      "   EnumClass.ONE  EnumClass.TWO  EnumClass.THREE  EnumClass.FOUR  \\\n",
      "0            5.1            3.5              1.4             0.2   \n",
      "1            4.9            3.0              1.4             0.2   \n",
      "2            4.7            3.2              1.3             0.2   \n",
      "3            4.6            3.1              1.5             0.2   \n",
      "4            5.0            3.6              1.4             0.2   \n",
      "\n",
      "  EnumClass.FIVE  \n",
      "0         setosa  \n",
      "1         setosa  \n",
      "2         setosa  \n",
      "3         setosa  \n",
      "4         setosa  \n"
     ]
    }
   ],
   "source": [
    "# 컬럼의 값을 바꾸는 건 2가지 방법이 있다.\n",
    "\n",
    "# (1) 많은 사람들이 쓰는 방법\n",
    "iris.columns = [1, 2, 3, 4, 5]\n",
    "print(iris, \"\\n\")\n",
    "\n",
    "# 컬럼 사이즈와 크기가 같은 Iterable한 객체를 대입하는 것이다.\n",
    "# 많은 사람들이 list만 쓰겠지만, 사실 tuple도 되는 것 봐서 여러가지가 올 수 있을 것 같아서 document를 봤다.\n",
    "# Index or array-like 란다. 당연히 array-like스러운 tuple, range에도 인덱스가 있으니 가능하다. 열거형인 Enum도 가능하다. Iterable한 객체이면 되는 듯 하다.\n",
    "tuple_obj: Iterable[int] = (1, 2, 3, 4, 5)\n",
    "iris.columns = tuple_obj\n",
    "print(iris, \"\\n\")\n",
    "\n",
    "range_obj: Iterable[int] = range(0, 5, 1)\n",
    "iris.columns = range_obj\n",
    "print(iris, \"\\n\")\n",
    "\n",
    "\n",
    "# python >= 3.4\n",
    "from enum import Enum\n",
    "\n",
    "class EnumClass(Enum):\n",
    "    ONE = 1\n",
    "    TWO = 2\n",
    "    THREE = 3\n",
    "    FOUR = 4\n",
    "    FIVE = 5\n",
    "\n",
    "# 열거형 object가 Iterable한 객체인지 확인\n",
    "if isinstance(EnumClass, Iterable):\n",
    "    print(\"Enum을 상속받은 EnumClass는 Iterable한 객체!\\n\")\n",
    "\n",
    "iris.columns = EnumClass\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmapper\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Renamer | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Renamer | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Renamer | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Axis | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Level'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IgnoreRaise'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame | None'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Alter axes labels.\n",
      "\n",
      "Function / dict values must be unique (1-to-1). Labels not contained in\n",
      "a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      "error.\n",
      "\n",
      "See the :ref:`user guide <basics.rename>` for more.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "mapper : dict-like or function\n",
      "    Dict-like or function transformations to apply to\n",
      "    that axis' values. Use either ``mapper`` and ``axis`` to\n",
      "    specify the axis to target with ``mapper``, or ``index`` and\n",
      "    ``columns``.\n",
      "index : dict-like or function\n",
      "    Alternative to specifying axis (``mapper, axis=0``\n",
      "    is equivalent to ``index=mapper``).\n",
      "columns : dict-like or function\n",
      "    Alternative to specifying axis (``mapper, axis=1``\n",
      "    is equivalent to ``columns=mapper``).\n",
      "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "    Axis to target with ``mapper``. Can be either the axis name\n",
      "    ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      "copy : bool, default True\n",
      "    Also copy underlying data.\n",
      "inplace : bool, default False\n",
      "    Whether to modify the DataFrame rather than creating a new one.\n",
      "    If True then value of copy is ignored.\n",
      "level : int or level name, default None\n",
      "    In case of a MultiIndex, only rename labels in the specified\n",
      "    level.\n",
      "errors : {'ignore', 'raise'}, default 'ignore'\n",
      "    If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      "    or `columns` contains labels that are not present in the Index\n",
      "    being transformed.\n",
      "    If 'ignore', existing keys will be renamed and extra keys will be\n",
      "    ignored.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame or None\n",
      "    DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      "\n",
      "Raises\n",
      "------\n",
      "KeyError\n",
      "    If any of the labels is not found in the selected axis and\n",
      "    \"errors='raise'\".\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.rename_axis : Set the name of the axis.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "``DataFrame.rename`` supports two calling conventions\n",
      "\n",
      "* ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      "* ``(mapper, axis={'index', 'columns'}, ...)``\n",
      "\n",
      "We *highly* recommend using keyword arguments to clarify your\n",
      "intent.\n",
      "\n",
      "Rename columns using a mapping:\n",
      "\n",
      ">>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      ">>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      "   a  c\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "\n",
      "Rename index using a mapping:\n",
      "\n",
      ">>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      "   A  B\n",
      "x  1  4\n",
      "y  2  5\n",
      "z  3  6\n",
      "\n",
      "Cast index labels to a different type:\n",
      "\n",
      ">>> df.index\n",
      "RangeIndex(start=0, stop=3, step=1)\n",
      ">>> df.rename(index=str).index\n",
      "Index(['0', '1', '2'], dtype='object')\n",
      "\n",
      ">>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      "Traceback (most recent call last):\n",
      "KeyError: ['C'] not found in axis\n",
      "\n",
      "Using axis-style parameters:\n",
      "\n",
      ">>> df.rename(str.lower, axis='columns')\n",
      "   a  b\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "\n",
      ">>> df.rename({1: 2, 2: 4}, axis='index')\n",
      "   A  B\n",
      "0  1  4\n",
      "2  2  5\n",
      "4  3  6\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\wnhon\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\n",
      "\u001b[1;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "# (2) 사람들이 잘 모르는 방법\n",
    "iris.rename?\n",
    "\n",
    "# iris.rename에 mapper(key: value) 타입의 객체를 넣어주어 하는 방법. \n",
    "# 보통 데이터프레임에는 axis가 있어 축을 설정 할 수 있다.\n",
    "\n",
    "# 내가 이 방법을 좋아하는 raw 데이터가 있을 때 원본 데이터의 column명을 지정해서 바꾸기 때문이다.\n",
    "# 위 columns는 바꿀 컬럼명의 순서가 일치해야 하지만, 얘는 매핑해서 넣기 때문에 순서가 뒤바껴도 상관없다.\n",
    "\n",
    "# 두번째로 columns = [] 는 바꾸고 싶은 컬럼명이든 그렇지 않은 컬럼명이든 무조건 넣어서 container의 사이즈를 맞춰줘야 하는 데,\n",
    "# 이 친구는 그렇게 하지 않아도 된다. 다음 예제를 보길."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>3</th>\n",
       "      <th>d</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a    b    3    d       5\n",
       "1000  5.1  3.5  1.4  0.2  setosa\n",
       "1001  4.9  3.0  1.4  0.2  setosa\n",
       "1002  4.7  3.2  1.3  0.2  setosa\n",
       "1003  4.6  3.1  1.5  0.2  setosa\n",
       "1004  5.0  3.6  1.4  0.2  setosa"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.rename({4: \"d\", 1: \"a\", 2: \"b\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마지막으로 나의 조언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 쓰면서 데이터프레임 객체 생성하고 자꾸 transform 시킨 객체를 새로운 객체에 대입하는 코드가 많다.\n",
    "\n",
    "# 예를 들면 이런 코드 (1)\n",
    "iris = iris.reset_index(drop=True)\n",
    "\n",
    "# 예를 들면 이런 코드 (2)\n",
    "iris = iris.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메모리 주소 :  2232523190768\n",
      "메모리 주소 :  2232523182800\n"
     ]
    }
   ],
   "source": [
    "# 그런데 이런 코드 실행할 때마다 메모리 주소가 바뀐다. \n",
    "iris = iris.reset_index(drop=True)\n",
    "print(\"메모리 주소 : \", id(iris))\n",
    "\n",
    "iris = iris.reset_index(drop=True)\n",
    "print(\"메모리 주소 : \", id(iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n.. deprecated:: 1.4.0\\n    Use :func:`concat` instead. For further details see\\n    :ref:`whatsnew_140.deprecations.frame_series_append`\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Append rows of `other` to the end of caller, returning a new object.\n",
      "\n",
      ".. deprecated:: 1.4.0\n",
      "    Use :func:`concat` instead. For further details see\n",
      "    :ref:`whatsnew_140.deprecations.frame_series_append`\n",
      "\n",
      "Columns in `other` that are not in the caller are added as new columns.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "other : DataFrame or Series/dict-like object, or list of these\n",
      "    The data to append.\n",
      "ignore_index : bool, default False\n",
      "    If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      "verify_integrity : bool, default False\n",
      "    If True, raise ValueError on creating index with duplicates.\n",
      "sort : bool, default False\n",
      "    Sort columns if the columns of `self` and `other` are not aligned.\n",
      "\n",
      "    .. versionchanged:: 1.0.0\n",
      "\n",
      "        Changed to not sort by default.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame\n",
      "    A new DataFrame consisting of the rows of caller and the rows of `other`.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "concat : General function to concatenate DataFrame or Series objects.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "If a list of dict/series is passed and the keys are all contained in\n",
      "the DataFrame's index, the order of the columns in the resulting\n",
      "DataFrame will be unchanged.\n",
      "\n",
      "Iteratively appending rows to a DataFrame can be more computationally\n",
      "intensive than a single concatenate. A better solution is to append\n",
      "those rows to a list and then concatenate the list with the original\n",
      "DataFrame all at once.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'), index=['x', 'y'])\n",
      ">>> df\n",
      "   A  B\n",
      "x  1  2\n",
      "y  3  4\n",
      ">>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'), index=['x', 'y'])\n",
      ">>> df.append(df2)\n",
      "   A  B\n",
      "x  1  2\n",
      "y  3  4\n",
      "x  5  6\n",
      "y  7  8\n",
      "\n",
      "With `ignore_index` set to True:\n",
      "\n",
      ">>> df.append(df2, ignore_index=True)\n",
      "   A  B\n",
      "0  1  2\n",
      "1  3  4\n",
      "2  5  6\n",
      "3  7  8\n",
      "\n",
      "The following, while not recommended methods for generating DataFrames,\n",
      "show two ways to generate a DataFrame from multiple data sources.\n",
      "\n",
      "Less efficient:\n",
      "\n",
      ">>> df = pd.DataFrame(columns=['A'])\n",
      ">>> for i in range(5):\n",
      "...     df = df.append({'A': i}, ignore_index=True)\n",
      ">>> df\n",
      "   A\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "3  3\n",
      "4  4\n",
      "\n",
      "More efficient:\n",
      "\n",
      ">>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      "...           ignore_index=True)\n",
      "   A\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "3  3\n",
      "4  4\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\wnhon\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.append?\n",
    "\n",
    "\"\"\"\n",
    ".. deprecated:: 1.4.0\n",
    "    Use :func:`concat` instead. For further details see\n",
    "    :ref:`whatsnew_140.deprecations.frame_series_append`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.append가 왜 deprecated 됬을 까?\n",
    "# 이유는 copy 때문이다. pd.DataFrame.append는 내부적으로 dataframe을 복제(copy)하여 행을 추가해서 반환하는 함수이다.\n",
    "\n",
    "# 이게 무슨 말이나면, 순간적이긴 하나 heap이랑 stack의 영역에 데이터프레임이 두 개 생긴다는 것이다.\n",
    "# 당연히 지금은 작은 데이터로도 잘 돌아가니 문제 없어 보이는 데, 만약 데이터가 크면 어떨 까?\n",
    "# 만약 5G 짜리 데이터프레임이 순간적으로 하나 더 생기면 당신의 컴퓨터는 감당할 수 있는 가?\n",
    "\n",
    "## etc : 5G vs 5GiB  ~ 차이가 있습니다. 알아두시면 좋습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전에 썼던 데이터프레임을 재반복 사용한다면 상관없다.\n",
    "# 그런데 보통 전처리 과정은 DAG(Directed Acyclic Graph) 형태로 비순환 그래프로 처리하기 때문에\n",
    "# 이전에 사용했던 객체를 메모리에서 할당해제하거나 같은 메모리를 계속 사용하게 만들어줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobjs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Iterable[NDFrame] | Mapping[HashableT, NDFrame]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Axis'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame | Series'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Concatenate pandas objects along a particular axis.\n",
      "\n",
      "Allows optional set logic along the other axes.\n",
      "\n",
      "Can also add a layer of hierarchical indexing on the concatenation axis,\n",
      "which may be useful if the labels are the same (or overlapping) on\n",
      "the passed axis number.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "objs : a sequence or mapping of Series or DataFrame objects\n",
      "    If a mapping is passed, the sorted keys will be used as the `keys`\n",
      "    argument, unless it is passed, in which case the values will be\n",
      "    selected (see below). Any None objects will be dropped silently unless\n",
      "    they are all None in which case a ValueError will be raised.\n",
      "axis : {0/'index', 1/'columns'}, default 0\n",
      "    The axis to concatenate along.\n",
      "join : {'inner', 'outer'}, default 'outer'\n",
      "    How to handle indexes on other axis (or axes).\n",
      "ignore_index : bool, default False\n",
      "    If True, do not use the index values along the concatenation axis. The\n",
      "    resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "    concatenating objects where the concatenation axis does not have\n",
      "    meaningful indexing information. Note the index values on the other\n",
      "    axes are still respected in the join.\n",
      "keys : sequence, default None\n",
      "    If multiple levels passed, should contain tuples. Construct\n",
      "    hierarchical index using the passed keys as the outermost level.\n",
      "levels : list of sequences, default None\n",
      "    Specific levels (unique values) to use for constructing a\n",
      "    MultiIndex. Otherwise they will be inferred from the keys.\n",
      "names : list, default None\n",
      "    Names for the levels in the resulting hierarchical index.\n",
      "verify_integrity : bool, default False\n",
      "    Check whether the new concatenated axis contains duplicates. This can\n",
      "    be very expensive relative to the actual data concatenation.\n",
      "sort : bool, default False\n",
      "    Sort non-concatenation axis if it is not already aligned when `join`\n",
      "    is 'outer'.\n",
      "    This has no effect when ``join='inner'``, which already preserves\n",
      "    the order of the non-concatenation axis.\n",
      "\n",
      "    .. versionchanged:: 1.0.0\n",
      "\n",
      "       Changed to not sort by default.\n",
      "\n",
      "copy : bool, default True\n",
      "    If False, do not copy data unnecessarily.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "object, type of objs\n",
      "    When concatenating all ``Series`` along the index (axis=0), a\n",
      "    ``Series`` is returned. When ``objs`` contains at least one\n",
      "    ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
      "    the columns (axis=1), a ``DataFrame`` is returned.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.join : Join DataFrames using indexes.\n",
      "DataFrame.merge : Merge DataFrames by indexes or columns.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The keys, levels, and names arguments are all optional.\n",
      "\n",
      "A walkthrough of how this method fits in with other tools for combining\n",
      "pandas objects can be found `here\n",
      "<https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
      "\n",
      "It is not recommended to build DataFrames by adding single rows in a\n",
      "for loop. Build a list of rows and make a DataFrame in a single concat.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Combine two ``Series``.\n",
      "\n",
      ">>> s1 = pd.Series(['a', 'b'])\n",
      ">>> s2 = pd.Series(['c', 'd'])\n",
      ">>> pd.concat([s1, s2])\n",
      "0    a\n",
      "1    b\n",
      "0    c\n",
      "1    d\n",
      "dtype: object\n",
      "\n",
      "Clear the existing index and reset it in the result\n",
      "by setting the ``ignore_index`` option to ``True``.\n",
      "\n",
      ">>> pd.concat([s1, s2], ignore_index=True)\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "dtype: object\n",
      "\n",
      "Add a hierarchical index at the outermost level of\n",
      "the data with the ``keys`` option.\n",
      "\n",
      ">>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
      "s1  0    a\n",
      "    1    b\n",
      "s2  0    c\n",
      "    1    d\n",
      "dtype: object\n",
      "\n",
      "Label the index keys you create with the ``names`` option.\n",
      "\n",
      ">>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
      "...           names=['Series name', 'Row ID'])\n",
      "Series name  Row ID\n",
      "s1           0         a\n",
      "             1         b\n",
      "s2           0         c\n",
      "             1         d\n",
      "dtype: object\n",
      "\n",
      "Combine two ``DataFrame`` objects with identical columns.\n",
      "\n",
      ">>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
      "...                    columns=['letter', 'number'])\n",
      ">>> df1\n",
      "  letter  number\n",
      "0      a       1\n",
      "1      b       2\n",
      ">>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
      "...                    columns=['letter', 'number'])\n",
      ">>> df2\n",
      "  letter  number\n",
      "0      c       3\n",
      "1      d       4\n",
      ">>> pd.concat([df1, df2])\n",
      "  letter  number\n",
      "0      a       1\n",
      "1      b       2\n",
      "0      c       3\n",
      "1      d       4\n",
      "\n",
      "Combine ``DataFrame`` objects with overlapping columns\n",
      "and return everything. Columns outside the intersection will\n",
      "be filled with ``NaN`` values.\n",
      "\n",
      ">>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
      "...                    columns=['letter', 'number', 'animal'])\n",
      ">>> df3\n",
      "  letter  number animal\n",
      "0      c       3    cat\n",
      "1      d       4    dog\n",
      ">>> pd.concat([df1, df3], sort=False)\n",
      "  letter  number animal\n",
      "0      a       1    NaN\n",
      "1      b       2    NaN\n",
      "0      c       3    cat\n",
      "1      d       4    dog\n",
      "\n",
      "Combine ``DataFrame`` objects with overlapping columns\n",
      "and return only those that are shared by passing ``inner`` to\n",
      "the ``join`` keyword argument.\n",
      "\n",
      ">>> pd.concat([df1, df3], join=\"inner\")\n",
      "  letter  number\n",
      "0      a       1\n",
      "1      b       2\n",
      "0      c       3\n",
      "1      d       4\n",
      "\n",
      "Combine ``DataFrame`` objects horizontally along the x axis by\n",
      "passing in ``axis=1``.\n",
      "\n",
      ">>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
      "...                    columns=['animal', 'name'])\n",
      ">>> pd.concat([df1, df4], axis=1)\n",
      "  letter  number  animal    name\n",
      "0      a       1    bird   polly\n",
      "1      b       2  monkey  george\n",
      "\n",
      "Prevent the result from including duplicate index values with the\n",
      "``verify_integrity`` option.\n",
      "\n",
      ">>> df5 = pd.DataFrame([1], index=['a'])\n",
      ">>> df5\n",
      "   0\n",
      "a  1\n",
      ">>> df6 = pd.DataFrame([2], index=['a'])\n",
      ">>> df6\n",
      "   0\n",
      "a  2\n",
      ">>> pd.concat([df5, df6], verify_integrity=True)\n",
      "Traceback (most recent call last):\n",
      "    ...\n",
      "ValueError: Indexes have overlapping values: ['a']\n",
      "\n",
      "Append a single row to the end of a ``DataFrame`` object.\n",
      "\n",
      ">>> df7 = pd.DataFrame({'a': 1, 'b': 2}, index=[0])\n",
      ">>> df7\n",
      "    a   b\n",
      "0   1   2\n",
      ">>> new_row = pd.Series({'a': 3, 'b': 4})\n",
      ">>> new_row\n",
      "a    3\n",
      "b    4\n",
      "dtype: int64\n",
      ">>> pd.concat([df7, new_row.to_frame().T], ignore_index=True)\n",
      "    a   b\n",
      "0   1   2\n",
      "1   3   4\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\wnhon\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "pd.concat?\n",
    "\n",
    "# pd.concat은 데이터프레임을 병합할 때 copy 옵션을 줘서 새로운 데이터프레임을 만드는 게 아닌, 기존 데이터프레임을 그대로 붙일 수 있다.\n",
    "# 물론 그대로 붙이기 때문에 두 데이터프레임을 담은 변수에 변화가 일어나지 않게 유의해야 할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임을 쓴다면 code를 이렇게 쓰는 것을 추천한다.\n",
    "iris.reset_index(drop=True, inplace=True)\n",
    "iris.drop_duplicates(inplace=True)\n",
    "# inplace 옵션이 있다면 추가해서 True를 주어라. 대부분 default value로 False가 지정 되어 있을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 같은 방식으로 쓰면\n",
    "iris = iris.reset_index(drop=True)\n",
    "iris = iris.drop_duplicates()\n",
    "# 이렇게 다시 변수에 할당하는 코드 안 쓰고 적용된다. 코드도 훨씬 간결해진다.\n",
    "\n",
    "# drop() method를 호출해서 어차피 index만 초기화 할 껀데, 뭐하러 객체의 memory address를 바꿀 껀가?\n",
    "# 물론 iris = iris.reset_index(drop=True) 이 까지는 원래 변수에 재 할당을 하니 기존의 memory address를 참조하는 변수가\n",
    "# 다른 memory address를 참조하게 되어 기존 메모리가 할당 해제되어 큰 문제는 없겠다.\n",
    "\n",
    "# 그런데\n",
    "iris2 = iris.reset_index(drop=True)\n",
    "iris3 = iris2.drop_duplicates()\n",
    "# 이렇게 transform을 주면서 매번 새로운 변수를 생성하여 할당하면\n",
    "# heap, stack 메모리 관리를 제대로 못하는 코드이기 때문에 메모리가 쌓여 OOM(Out Of Memory) 에러가 발생한다.\n",
    "\n",
    "# 결론 DataFrame 클래스 내부의 메서드 중에 inplace 옵션이 있다면 적극 활용하자.\n",
    "# 음.. pd.Series, loc/iloc, apply function을 설명하고 싶지만 글이 길어져서 각자 잘 공부하리라 믿는다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68d3b10d79c6e02d0d1f7bb5595fc6acdd9cd892dc842c813ff1c5403a22a80c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
